{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import re\n",
    "import os\n",
    "from pathlib import Path\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify required input\n",
    "\n",
    "# Add SynFlow to path in order to import modules\n",
    "repo_root = \"/home/volt/bach/SynFlow\"\n",
    "if repo_root not in sys.path:\n",
    "    sys.path.insert(0, repo_root)\n",
    "\n",
    "# Regex corpus_pattern to extract relevant information from CoNLL-U files\n",
    "corpus_pattern = re.compile(\n",
    "    r'([^\\t]+)\\t'      # word form\n",
    "    r'([^\\t]+)\\t'      # lemma\n",
    "    r'([^\\t])[^\\t]*\\t' # POS (UPOS or XPOS)\n",
    "    r'([^\\t]+)\\t'      # ID\n",
    "    r'([^\\t]+)\\t'      # HEAD\n",
    "    r'([^\\t]+)'        # DEPREL\n",
    ")\n",
    "\n",
    "# Specify target lemma and part of speech\n",
    "target_lemma = 'air'\n",
    "target_pos = 'N'\n",
    "\n",
    "# Specify corpus and output folders\n",
    "period = '1750-1819'\n",
    "corpus_folder = f'/home/volt/bach/pilot_data/RSC/1750-1819_che_half_decades'\n",
    "output_folder = Path(f'/home/volt/bach/SynFlow/case_studies/RSC_air_water_acid/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dont change below this line\n",
    "output_folder_lemma = output_folder / 'output' / f'{target_lemma}-{target_pos}-{period}'\n",
    "output_explorer = f'{output_folder_lemma}/Explorer'\n",
    "output_embedding = f'{output_folder_lemma}/Embedding'\n",
    "input_SCD = output_folder / 'input' / 'SCD' /f'{target_lemma}-{target_pos}-{period}'\n",
    "\n",
    "os.makedirs(output_explorer, exist_ok=True)\n",
    "os.makedirs(output_embedding, exist_ok=True)\n",
    "os.makedirs(input_SCD, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the vocab freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SynFlow.Explorer.vocab_freq import gen_lemma_freq, analyze_corpus_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_lemma_freq(corpus_folder, \n",
    "               '/home/volt/bach/pilot_data/RSC/1750-1819_che_half_decades_vocab', # Output folder for vocab files\n",
    "               file_ext='.txt', mode='lemma_pos_init') # modes: 'lemma_pos', 'lemma_pos_init', or 'lemma_deprel'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_corpus_vocab('/home/volt/bach/pilot_data/RSC/1750-1819_che_half_decades_vocab')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the distribution of different syntactic slots from the corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slot-path Explorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SynFlow.Explorer import spath_explorer\n",
    "dist = spath_explorer(\n",
    "    corpus_folder=corpus_folder,\n",
    "    target_lemma=target_lemma,\n",
    "    target_pos=target_pos,\n",
    "    max_length=1,\n",
    "    top_n=50,\n",
    "    pattern=corpus_pattern,\n",
    "    output_folder=output_explorer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unique Slot-path Combination Explorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 unique full-pattern string for 1 token\n",
    "from SynFlow.Explorer import spath_comb_explorer\n",
    "\n",
    "ctr = spath_comb_explorer(\n",
    "    corpus_folder=corpus_folder,\n",
    "    target_lemma=target_lemma,\n",
    "    target_pos=target_pos,\n",
    "    max_length=1,\n",
    "    top_n=30,\n",
    "    output_folder=output_explorer,\n",
    "    pattern=corpus_pattern\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rel Explorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SynFlow.Explorer import rel_explorer\n",
    "\n",
    "rel_explorer_results = rel_explorer(\n",
    "    corpus_folder=corpus_folder,\n",
    "    pattern=corpus_pattern,            # or leave None to use default\n",
    "    target_lemma=target_lemma,\n",
    "    target_pos=target_pos,\n",
    "    rel=\"pa_nsubj\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname, sent, sfillers, path in rel_explorer_results[:10000]:\n",
    "    # ctx_list là một list các \"lemma/pos\", nối bằng ' > ' để in cho dễ nhìn\n",
    "    sfillers = \" > \".join(sfillers)\n",
    "    print(f\"{fname:15} | {path:10} | {sfillers:15} | {sent}\")\n",
    "\n",
    "# Save to csv\n",
    "import csv\n",
    "out_path = f'{output_explorer}/rel_explorer.tsv'\n",
    "with open(out_path, \"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "    w = csv.writer(f, delimiter='\\t')\n",
    "    w.writerow([\"file\", \"path\", \"sfillers\", \"sentence\"])\n",
    "    for fname, sent, sfillers, path in rel_explorer_results:\n",
    "        sfillers = \" > \".join(sfillers)\n",
    "        w.writerow([fname, path, sfillers, sent])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Rel Explorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SynFlow.Explorer import full_rel_explorer\n",
    "\n",
    "full_rel_explorer_results = full_rel_explorer(\n",
    "    corpus_folder=corpus_folder,\n",
    "    pattern=corpus_pattern,            # or leave None to use default\n",
    "    target_lemma=target_lemma,\n",
    "    target_pos=target_pos,\n",
    "    rel=\"chi_case & chi_det & pa_obl\",\n",
    "    # rel=\"chi_aux & chi_nsubj & chi_obj & chi_punct\",\n",
    "    # rel=\"chi_discourse > chi_punct & chi_punct\",\n",
    "    mode = 'close', # 'open', 'close', 'closeh'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect a few\n",
    "sent_num = 0\n",
    "for fname, sent, paths_details_list in full_rel_explorer_results[:10]:\n",
    "    sent_num += 1\n",
    "    # paths_details_list is a list of (sfillers, path) tuples\n",
    "    for sfillers, path in paths_details_list:\n",
    "        # sfillers is a list of \"lemma/pos\", join using ' > ' to print\n",
    "        sfillers = \" > \".join(sfillers)\n",
    "        print(f\"{sent_num} | {fname:15} | {path:10} | {sfillers:15} | {sent}\")\n",
    "\n",
    "# Save to csv\n",
    "import csv\n",
    "out_path = f'{output_explorer}/full_rel_explorer.tsv'\n",
    "with open(out_path, \"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "    w = csv.writer(f, delimiter='\\t')\n",
    "    w.writerow([\"sent_num\", \"file\", \"path\", \"ctx_nodes\", \"sentence\"])\n",
    "    sent_num = 0\n",
    "    for fname, sent, paths_details_list in full_rel_explorer_results:\n",
    "        sent_num += 1\n",
    "        for sfillers, path in paths_details_list:\n",
    "            sfillers = \" > \".join(sfillers)\n",
    "            w.writerow([sent_num, fname, path, sfillers, sent])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trimming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('/home/volt/bach/SynFlow/case_studies/RSC_air_water_acid/output/air-N-1750-1819/Explorer/air_N_spath_combs_1_hops.csv', sep='&')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SynFlow.Explorer import trim_and_merge\n",
    "\n",
    "# Trim and merge relations\n",
    "spath_df = '/home/volt/bach/SynFlow/case_studies/RSC_air_water_acid/output/air-N-1750-1819/Explorer/air_N_spath_combs_1_hops.csv'\n",
    "trimmed_rels = ['chi_case']\n",
    "trim_and_merge(spath_df=spath_df, trimmed_rels=trimmed_rels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specialisations Grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SynFlow.Explorer.trimming import spe_group\n",
    "\n",
    "spath_df = '/home/volt/bach/SynFlow/case_studies/RSC_air_water_acid/output/air-N-1750-1819/Explorer/air_N_spath_combs_1_hops.csv'\n",
    "tree = spe_group(spath_df, output_folder=output_explorer, target_lemma=target_lemma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Slot-filler df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SynFlow.Explorer import build_sfiller_df\n",
    "\n",
    "sfiller_df = build_sfiller_df(\n",
    "    corpus_folder=corpus_folder,\n",
    "    template='[pa_conj]', # Example: '[chi_nsubj][chi_obj][chi_obl > chi_case]'\n",
    "    target_lemma=target_lemma,\n",
    "    target_pos=target_pos,\n",
    "    pattern=corpus_pattern,\n",
    "    # freq_path='/home/volt/bach/pilot_data/RSC/lemma_pos_init_freq.txt', # Be sure that the freq_path matches that of the filter format\n",
    "    # freq_min=1,\n",
    "    # freq_max=100_000_000,\n",
    "    filtered_pos=[],\n",
    "    filler_format='lemma/pos', # lemma/deprel or 'lemma/pos'\n",
    "    output_folder= output_embedding\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling from the general slots DataFrame\n",
    "from SynFlow.Explorer import sample_sfiller_df\n",
    "n = 5\n",
    "sfiller_sample_df = sample_sfiller_df(\n",
    "    input_csv=f\"{output_embedding}/{target_lemma}_samples_sfillerdf_all.csv\",\n",
    "    output_csv=f\"{output_embedding}/{target_lemma}_samples_sfillerdf_{n}.csv\",\n",
    "    n=n,\n",
    "    seed=42,\n",
    "    mode= 'NA'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bython311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
